{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaos/miniconda3/envs/chaos/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from utils.dataset import  Create_YOLO_Cache, YOLODataset\n",
    "yaml = '/home/chaos/Documents/ChaosAIVision/Build-YOLO-v1-from-scratch/data.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 7, 7, 30])\n"
     ]
    }
   ],
   "source": [
    "dataset= YOLODataset('train', yaml,7,2,20,True)\n",
    "a,b  = dataset.__getitem__(6)\n",
    "b = b.unsqueeze(0)  # Thêm chiều batch size\n",
    "\n",
    "print((b.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Loss(nn.Module):\n",
    "    def __init__(self, S, B, l_coord, l_noobj):\n",
    "        super(Loss, self).__init__()\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.l_coord = l_coord\n",
    "        self.l_noobj = l_noobj\n",
    "\n",
    "    def compute_iou(self, box1, box2):\n",
    "        N = box1.size(0)\n",
    "        M = box2.size(0)\n",
    "\n",
    "        lt = torch.max(\n",
    "            box1[:, :2].unsqueeze(1).expand(N, M, 2),\n",
    "            box2[:, :2].unsqueeze(0).expand(N, M, 2),\n",
    "        )\n",
    "\n",
    "        rb = torch.min(\n",
    "            box1[:, 2:].unsqueeze(1).expand(N, M, 2),\n",
    "            box2[:, 2:].unsqueeze(0).expand(N, M, 2),\n",
    "        )\n",
    "\n",
    "        wh = rb - lt\n",
    "        wh[wh < 0] = 0\n",
    "        inter = wh[:, :, 0] * wh[:, :, 1]\n",
    "\n",
    "        area1 = (box1[:, 2] - box1[:, 0]) * (box1[:, 3] - box1[:, 1])\n",
    "        area2 = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])\n",
    "        area1 = area1.unsqueeze(1).expand_as(inter)\n",
    "        area2 = area2.unsqueeze(0).expand_as(inter)\n",
    "\n",
    "        iou = inter / (area1 + area2 - inter)\n",
    "        return iou\n",
    "\n",
    "    def forward(self, prediction, target):\n",
    "        device = prediction\n",
    "\n",
    "        N = prediction.size(0)\n",
    "        coo_mask = target[:, :, :, 4] > 0\n",
    "        noo_mask = target[:, :, :, 4] == 0\n",
    "        coo_mask = coo_mask.unsqueeze(-1).expand_as(target)\n",
    "        noo_mask = noo_mask.unsqueeze(-1).expand_as(target)\n",
    "\n",
    "        coo_pred = prediction[coo_mask].view(-1, 30)\n",
    "        box_pred = coo_pred[:, :10].contiguous().view(-1, 5)\n",
    "        class_pred = coo_pred[:, 10:]\n",
    "\n",
    "        coo_target = target[coo_mask].view(-1, 30)\n",
    "        box_target = coo_target[:, :10].contiguous().view(-1, 5)\n",
    "        class_target = coo_target[:, 10:]\n",
    "\n",
    "        # Đưa tất cả tensor vào đúng thiết bị\n",
    "        noo_mask = noo_mask.to(device)\n",
    "        noo_pred = prediction[noo_mask].view(-1, 30)\n",
    "        noo_target = target[noo_mask].view(-1, 30)\n",
    "        \n",
    "        # Đảm bảo mặt nạ được tạo trên thiết bị đúng\n",
    "        noo_pred_mask = torch.zeros(noo_pred.size(), dtype=torch.bool, device=device)\n",
    "        noo_pred_mask[:, 4] = 1\n",
    "        noo_pred_mask[:, 9] = 1\n",
    "        noo_pred_c = noo_pred[noo_pred_mask]\n",
    "        noo_target_c = noo_target[noo_pred_mask]\n",
    "        nooobj_loss = F.mse_loss(noo_pred_c, noo_target_c, reduction='sum')\n",
    "\n",
    "        coo_response_mask = torch.zeros(box_target.size(), dtype=torch.bool, device=device)\n",
    "        coo_not_response_mask = torch.zeros(box_target.size(), dtype=torch.bool, device=device)\n",
    "        box_target_iou = torch.zeros(box_target.size(), device=device)\n",
    "        \n",
    "        for i in range(0, box_target.size(0), 2):\n",
    "            box1 = box_pred[i:i + 2]\n",
    "            box1_xyxy = torch.zeros(box1.size(), device=device)\n",
    "            box1_xyxy[:, :2] = box1[:, :2] / 14. - 0.5 * box1[:, 2:4]\n",
    "            box1_xyxy[:, 2:4] = box1[:, :2] / 14. + 0.5 * box1[:, 2:4]\n",
    "            box2 = box_target[i].view(-1, 5)\n",
    "            box2_xyxy = torch.zeros(box2.size(), device=device)\n",
    "            box2_xyxy[:, :2] = box2[:, :2] / 14. - 0.5 * box2[:, 2:4]\n",
    "            box2_xyxy[:, 2:4] = box2[:, :2] / 14. + 0.5 * box2[:, 2:4]\n",
    "            iou = self.compute_iou(box1_xyxy[:, :4], box2_xyxy[:, :4])\n",
    "            print(iou)\n",
    "            max_iou, max_index = iou.max(0)\n",
    "            max_index = max_index.to(device)\n",
    "\n",
    "            coo_response_mask[i + max_index] = 1\n",
    "            coo_not_response_mask[i + 1 - max_index] = 1\n",
    "\n",
    "            box_target_iou[i + max_index, torch.tensor([4], device=device)] = max_iou.to(device)\n",
    "        \n",
    "        \"\"\"Loss tính toán\"\"\"\n",
    "        box_pred_response = box_pred[coo_response_mask].view(-1, 5)\n",
    "        box_target_response_iou = box_target_iou[coo_response_mask].view(-1, 5)\n",
    "        box_target_response = box_target[coo_response_mask].view(-1, 5)\n",
    "        contain_loss = F.mse_loss(box_pred_response[:, 4], box_target_response_iou[:, 4], reduction='sum')\n",
    "        loc_loss = F.mse_loss(box_pred_response[:, :2], box_target_response[:, :2], reduction='sum') + F.mse_loss(\n",
    "            torch.sqrt(box_pred_response[:, 2:4]), torch.sqrt(box_target_response[:, 2:4]), reduction='sum')\n",
    "        \n",
    "        box_pred_not_response = box_pred[coo_not_response_mask].view(-1, 5)\n",
    "        box_target_not_response = box_target[coo_not_response_mask].view(-1, 5)\n",
    "        box_target_not_response[:, 4] = 0\n",
    "\n",
    "        not_contain_loss = F.mse_loss(box_pred_not_response[:, 4], box_target_not_response[:, 4], reduction='sum')\n",
    "\n",
    "        class_loss = F.mse_loss(class_pred, class_target, reduction='sum')\n",
    "\n",
    "        loss = self.l_coord * loc_loss + 2 * contain_loss + not_contain_loss + self.l_noobj * nooobj_loss + class_loss\n",
    "\n",
    "        return loss / N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, int, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 15\u001b[0m\n\u001b[1;32m     10\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m Loss(S\u001b[38;5;241m=\u001b[39mS, B\u001b[38;5;241m=\u001b[39mB, l_coord\u001b[38;5;241m=\u001b[39ml_coord, l_noobj\u001b[38;5;241m=\u001b[39ml_noobj)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComputed loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/chaos/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/chaos/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[27], line 58\u001b[0m, in \u001b[0;36mLoss.forward\u001b[0;34m(self, prediction, target)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Đưa tất cả tensor vào đúng thiết bị\u001b[39;00m\n\u001b[1;32m     57\u001b[0m noo_mask \u001b[38;5;241m=\u001b[39m noo_mask\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 58\u001b[0m noo_pred \u001b[38;5;241m=\u001b[39m \u001b[43mprediction\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnoo_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m     59\u001b[0m noo_target \u001b[38;5;241m=\u001b[39m target[noo_mask]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Đảm bảo mặt nạ được tạo trên thiết bị đúng\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, int, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define parameters\n",
    "S = 7  # Grid size\n",
    "B = 2  # Number of bounding boxes\n",
    "l_coord = 5.0  # Weight for coordinate loss\n",
    "l_noobj = 0.5  # Weight for \"no object\" loss\n",
    "\n",
    "# Create an instance of the Loss class\n",
    "loss_fn = Loss(S=S, B=B, l_coord=l_coord, l_noobj=l_noobj)\n",
    "\n",
    "\n",
    "\n",
    "# Compute the loss\n",
    "loss = loss_fn(b, b)\n",
    "\n",
    "print(f\"Computed loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class YOLOv1Loss(nn.Module):\n",
    "    def __init__(self, S=7, B=2, C=20):\n",
    "        \"\"\"\n",
    "        __init__ initialize YOLOv1 Loss.\n",
    "\n",
    "        Args:\n",
    "            S (int, optional): split_size. Defaults to 7.\n",
    "            B (int, optional): number of boxes. Defaults to 2.\n",
    "            C (int, optional): number of classes. Defaults to 20.\n",
    "        \"\"\" \n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.l_noobl = 0.5\n",
    "        self.l_coord = 5\n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B*5)\n",
    "\n",
    "        iou_b1 = get_iou(predictions[...,21:25], target[...,21:25])\n",
    "        iou_b2 = get_iou(predictions[...,26:30], target[...,21:25])\n",
    "        ious = torch.stack([iou_b1, iou_b2], 0)\n",
    "\n",
    "        _, max_iou = torch.max(ious, dim=0)\n",
    "        exists_box = target[...,20].unsqueeze(3) # select target objectness.object\n",
    "\n",
    "        # * Box Coordinates Loss\n",
    "\n",
    "        # Select the bounding boxes with highest IoU\n",
    "        box_predictions = exists_box * (\n",
    "            (\n",
    "                max_iou * predictions[..., 26:30] +\n",
    "                (1 - max_iou) * predictions[..., 21:25]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Select targets which has an object\n",
    "        box_targets = exists_box * target[...,21:25]\n",
    "\n",
    "        box_predictions[...,2:4] = torch.sign(box_predictions[...,2:4]) * torch.sqrt(\n",
    "            torch.abs(box_predictions[..., 2:4]) + 1e-6\n",
    "        )\n",
    "\n",
    "        box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])\n",
    "\n",
    "        box_loss = self.mse(\n",
    "            torch.flatten(box_predictions, end_dim=-2),\n",
    "            torch.flatten(box_targets, end_dim=-2)\n",
    "        )\n",
    "\n",
    "        # * Object Losss\n",
    "\n",
    "        pred_box = (\n",
    "            max_iou * predictions[..., 25:26] + \n",
    "            (1-max_iou) * predictions[..., 20:21]\n",
    "        )\n",
    "\n",
    "        object_loss = self.mse(\n",
    "            torch.flatten(exists_box * pred_box),\n",
    "            torch.flatten(exists_box * target[..., 20:21])\n",
    "        )\n",
    "        # * No Object Loss\n",
    "        # For the first box\n",
    "        no_boject_loss = self.mse(\n",
    "            torch.flatten((1-max_iou) * predictions[...,20:21], start_dim=1),\n",
    "            torch.flatten((1-max_iou) * target[...,20:21], start_dim=1)\n",
    "        )\n",
    "        # For the second box\n",
    "        no_boject_loss += self.mse(\n",
    "            torch.flatten(max_iou * predictions[...,25:26], start_dim=1),\n",
    "            torch.flatten(max_iou * target[...,20:21], start_dim=1)\n",
    "        )\n",
    "        # * Class prediction Loss\n",
    "\n",
    "        class_loss = self.mse(\n",
    "            torch.flatten(exists_box * predictions[...,:20], end_dim=-2),\n",
    "            torch.flatten(exists_box * target[...,:20], end_dim=-2)\n",
    "        )\n",
    "\n",
    "        # * Total Loss\n",
    "        loss = (\n",
    "            self.l_coord * box_loss \n",
    "            + object_loss\n",
    "            + self.l_noobl * no_boject_loss\n",
    "            + class_loss\n",
    "        )\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "def get_iou(box1, box2, box_format=\"midpoint\"):\n",
    "    \"\"\"\n",
    "        Calculates intersection over union\n",
    "        Parameters:\n",
    "            boxes1 (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n",
    "            box2 (tensor): Correct Labels of Boxes (BATCH_SIZE, 4)\n",
    "            box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n",
    "        Returns:\n",
    "            tensor: Intersection over union for all examples\n",
    "    \"\"\"\n",
    "\n",
    "    if box_format == \"corners\":\n",
    "        # * box 1\n",
    "        box1_x1 = box1[...,0:1]\n",
    "        box1_y1 = box1[...,1:2]\n",
    "        box1_x2 = box1[...,2:3]\n",
    "        box1_y2 = box1[...,3:4]\n",
    "\n",
    "        # * box 2\n",
    "        box2_x1 = box2[...,0:1]\n",
    "        box2_y1 = box2[...,1:2]\n",
    "        box2_x2 = box2[...,2:3]\n",
    "        box2_y2 = box2[...,3:4]\n",
    "\n",
    "    elif box_format == \"midpoint\":\n",
    "        box1_x1 = box1[..., 0:1] - box1[..., 2:3] / 2\n",
    "        box1_y1 = box1[..., 1:2] - box1[..., 3:4] / 2\n",
    "        box1_x2 = box1[..., 0:1] + box1[..., 2:3] / 2\n",
    "        box1_y2 = box1[..., 1:2] + box1[..., 3:4] / 2\n",
    "        box2_x1 = box2[..., 0:1] - box2[..., 2:3] / 2\n",
    "        box2_y1 = box2[..., 1:2] - box2[..., 3:4] / 2\n",
    "        box2_x2 = box2[..., 0:1] + box2[..., 2:3] / 2\n",
    "        box2_y2 = box2[..., 1:2] + box2[..., 3:4] / 2\n",
    "    else:\n",
    "        raise NotImplementedError(f\"OOPs! {box_format} not supported!\")\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1)) \n",
    "\n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.7763568394002505e-12\n"
     ]
    }
   ],
   "source": [
    "yolo_loss = YOLOv1Loss()\n",
    "loss = yolo_loss(b, b)\n",
    "print(f\"Loss: {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_over_union(boxes_preds, boxes_labels, box_format=\"midpoint\"):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates intersection over union\n",
    "\n",
    "    Parameters:\n",
    "        boxes_preds (tensor): Predictions of Bounding Boxes (BATCH_SIZE, 4)\n",
    "        boxes_labels (tensor): Correct labels of Bounding Boxes (BATCH_SIZE, 4)\n",
    "        box_format (str): midpoint/corners, if boxes (x,y,w,h) or (x1,y1,x2,y2)\n",
    "\n",
    "    Returns:\n",
    "        tensor: Intersection over union for all examples\n",
    "    \"\"\"\n",
    "\n",
    "    if box_format == \"midpoint\":\n",
    "        box1_x1 = boxes_preds[..., 0:1] - boxes_preds[..., 2:3] / 2\n",
    "        box1_y1 = boxes_preds[..., 1:2] - boxes_preds[..., 3:4] / 2\n",
    "        box1_x2 = boxes_preds[..., 0:1] + boxes_preds[..., 2:3] / 2\n",
    "        box1_y2 = boxes_preds[..., 1:2] + boxes_preds[..., 3:4] / 2\n",
    "        box2_x1 = boxes_labels[..., 0:1] - boxes_labels[..., 2:3] / 2\n",
    "        box2_y1 = boxes_labels[..., 1:2] - boxes_labels[..., 3:4] / 2\n",
    "        box2_x2 = boxes_labels[..., 0:1] + boxes_labels[..., 2:3] / 2\n",
    "        box2_y2 = boxes_labels[..., 1:2] + boxes_labels[..., 3:4] / 2\n",
    "\n",
    "    if box_format == \"corners\":\n",
    "        box1_x1 = boxes_preds[..., 0:1]\n",
    "        box1_y1 = boxes_preds[..., 1:2]\n",
    "        box1_x2 = boxes_preds[..., 2:3]\n",
    "        box1_y2 = boxes_preds[..., 3:4]  # (N, 1)\n",
    "        box2_x1 = boxes_labels[..., 0:1]\n",
    "        box2_y1 = boxes_labels[..., 1:2]\n",
    "        box2_x2 = boxes_labels[..., 2:3]\n",
    "        box2_y2 = boxes_labels[..., 3:4]\n",
    "\n",
    "    x1 = torch.max(box1_x1, box2_x1)\n",
    "    y1 = torch.max(box1_y1, box2_y1)\n",
    "    x2 = torch.min(box1_x2, box2_x2)\n",
    "    y2 = torch.min(box1_y2, box2_y2)\n",
    "\n",
    "    # .clamp(0) is for the case when they do not intersect\n",
    "    intersection = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "\n",
    "    box1_area = abs((box1_x2 - box1_x1) * (box1_y2 - box1_y1))\n",
    "    box2_area = abs((box2_x2 - box2_x1) * (box2_y2 - box2_y1))\n",
    "\n",
    "    return intersection / (box1_area + box2_area - intersection + 1e-6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculate the loss for yolo (v1) model\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, S=7, B=2, C=20):\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "        \"\"\"\n",
    "        S is split size of image (in paper 7),\n",
    "        B is number of boxes (in paper 2),\n",
    "        C is number of classes (in paper and VOC dataset is 20),\n",
    "        \"\"\"\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "        # pay loss for no object (noobj) and the box coordinates (coord)\n",
    "        self.lambda_noobj = 0.5\n",
    "        self.lambda_coord = 5\n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        # predictions are shaped (BATCH_SIZE, S*S(C+B*5) when inputted\n",
    "        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 5)\n",
    "\n",
    "        # Calculate IoU for the two predicted bounding boxes with target bbox\n",
    "        iou_b1 = intersection_over_union(predictions[..., 21:25], target[..., 21:25])\n",
    "        iou_b2 = intersection_over_union(predictions[..., 26:30], target[..., 21:25])\n",
    "        ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)\n",
    "\n",
    "        # Take the box with highest IoU out of the two prediction\n",
    "        # Note that bestbox will be indices of 0, 1 for which bbox was best\n",
    "        iou_maxes, bestbox = torch.max(ious, dim=0)\n",
    "        exists_box = target[..., 20].unsqueeze(3) \n",
    "\n",
    "        # ======================== #\n",
    "        #   FOR BOX COORDINATES    #\n",
    "        # ======================== #\n",
    "\n",
    "        # Set boxes with no object in them to 0. We only take out one of the two \n",
    "        # predictions, which is the one with highest Iou calculated previously.\n",
    "        box_predictions = exists_box * (\n",
    "            (\n",
    "                bestbox * predictions[..., 26:30]\n",
    "                + (1 - bestbox) * predictions[..., 21:25]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        box_targets = exists_box * target[..., 21:25]\n",
    "\n",
    "        # Take sqrt of width, height of boxes to ensure that\n",
    "        box_predictions[..., 2:4] = torch.sign(box_predictions[..., 2:4]) * torch.sqrt(\n",
    "            torch.abs(box_predictions[..., 2:4] + 1e-6)\n",
    "        )\n",
    "        box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])\n",
    "        box_loss = self.mse(\n",
    "            torch.flatten(box_predictions, end_dim=-2),\n",
    "            torch.flatten(box_targets, end_dim=-2),\n",
    "        )\n",
    "        # ==================== #\n",
    "        #   FOR OBJECT LOSS    #\n",
    "        # ==================== #\n",
    "\n",
    "        # pred_box is the confidence score for the bbox with highest IoU\n",
    "        pred_box = (\n",
    "            bestbox * predictions[..., 25:26] + (1 - bestbox) * predictions[..., 20:21]\n",
    "        )\n",
    "\n",
    "        object_loss = self.mse(\n",
    "            torch.flatten(exists_box * pred_box),\n",
    "            torch.flatten(exists_box * target[..., 20:21]),\n",
    "        )\n",
    "\n",
    "        # ======================= #\n",
    "        #   FOR NO OBJECT LOSS    #\n",
    "        # ======================= #\n",
    "\n",
    "\n",
    "\n",
    "        no_object_loss = self.mse(\n",
    "            torch.flatten((1 - exists_box) * predictions[..., 20:21], start_dim=1),\n",
    "            torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1),\n",
    "        )\n",
    "\n",
    "        no_object_loss += self.mse(\n",
    "            torch.flatten((1 - exists_box) * predictions[..., 25:26], start_dim=1),\n",
    "            torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1)\n",
    "        )\n",
    "\n",
    "        # ================== #\n",
    "        #   FOR CLASS LOSS   #\n",
    "        # ================== #\n",
    "\n",
    "        class_loss = self.mse(\n",
    "            torch.flatten(exists_box * predictions[..., :20], end_dim=-2,),\n",
    "            torch.flatten(exists_box * target[..., :20], end_dim=-2,),\n",
    "        )\n",
    "        \n",
    "\n",
    "        loss = (\n",
    "            self.lambda_coord * box_loss \n",
    "            + object_loss \n",
    "            + self.lambda_noobj * no_object_loss \n",
    "            + class_loss \n",
    "        )\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "        return loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_loss1 = YoloLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.7764e-12)\n"
     ]
    }
   ],
   "source": [
    "loss = yolo_loss1(b, b)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLossv3(nn.Module):\n",
    "    def __init__(self, S=7, B=2, C=20):\n",
    "        super(YoloLossv3, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction = \"sum\")\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.lambda_noobj = 0.5\n",
    "        self.lambda_coord = 5\n",
    "\n",
    "    def forward(self, predictions, target):\n",
    "        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 5)\n",
    "\n",
    "        iou_b1 = intersection_over_union(predictions[..., 21:25], target[..., 21:25])\n",
    "        iou_b2 = intersection_over_union(predictions[..., 26:30], target[..., 21:25])\n",
    "        ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)\n",
    "\n",
    "        iou_maxes, bestbox = torch.max(ious, dim=0) # iou_maxes: là cái tensor có iou cao nhất, bestbox là argmax của iou cao nhất\n",
    "        exists_box = target[..., 20].unsqueeze(3) # I obj_j\n",
    "\n",
    "        # loss for box cooor - loss for box cooor - loss for box cooor \n",
    "        # box_prediction la` co box hay ko nhan cho box 1 hay 2\n",
    "        box_predictions = exists_box * (\n",
    "            (\n",
    "                bestbox * predictions[..., 26:30]\n",
    "                + (1 - bestbox) * predictions[..., 21:25]\n",
    "            ) \n",
    "        )\n",
    "        box_targets = exists_box * target[..., 21:25]\n",
    "        \n",
    "        box_predictions[..., 2:4] = torch.sign(box_predictions[..., 2:4]) * torch.sqrt(\n",
    "            torch.abs(box_predictions[..., 2:4] + 1e-6)\n",
    "        )\n",
    "        box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])\n",
    "\n",
    "        box_loss = self.mse(\n",
    "            torch.flatten(box_predictions, end_dim=-2), # B,S,S,(X,Y,W,H) --> (N*S*S, 4)\n",
    "            torch.flatten(box_targets, end_dim=-2),\n",
    "        )\n",
    "\n",
    "        # loss object class - loss object class - loss object class\n",
    "\n",
    "        pred_box = (\n",
    "            bestbox * predictions[..., 25:26] + (1 - bestbox) * predictions[..., 20:21]\n",
    "        )\n",
    "        object_loss = self.mse(\n",
    "            torch.flatten(exists_box * pred_box), # (B,S,S,1) --> (B*S*S,1)\n",
    "            torch.flatten(exists_box * target[..., 20:21]),\n",
    "        )\n",
    "\n",
    "        # loss no object class - loss no object class - loss no object class\n",
    "        pred_no_box = (\n",
    "             (1 - bestbox)  * predictions[..., 25:26] + bestbox* predictions[..., 20:21]\n",
    "        )\n",
    "        no_object_loss = self.mse(\n",
    "            torch.flatten((1 - exists_box) * pred_no_box, start_dim=1),\n",
    "            torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1),\n",
    "        )\n",
    "\n",
    "\n",
    "        # loss class - loss class - loss class\n",
    "        class_loss = self.mse(\n",
    "            torch.flatten(exists_box * predictions[..., :20], end_dim=-2,),#(N,S,S,20) --> (N*S*S, 20)\n",
    "            torch.flatten(exists_box * target[..., :20], end_dim=-2,),\n",
    "        )\n",
    "\n",
    "        loss = (\n",
    "            self.lambda_coord * box_loss  # first two rows in paper\n",
    "            + object_loss  # third row in paper\n",
    "            + self.lambda_noobj * no_object_loss  # forth row\n",
    "            + class_loss  # fifth row\n",
    "        )\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "def copy_files_from_excel(image_folder, label_folder, excel_path, output_folder):\n",
    "    # Đọc tệp Excel\n",
    "    df = pd.read_csv(excel_path)\n",
    "    \n",
    "    # Tạo thư mục đầu ra nếu chưa tồn tại\n",
    "    os.makedirs(os.path.join(output_folder, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_folder, 'labels'), exist_ok=True)\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        image_file = row['image']\n",
    "        label_file = row['text']\n",
    "        \n",
    "        # Tạo đường dẫn đầy đủ đến các tệp nguồn\n",
    "        image_source_path = os.path.join(image_folder, image_file)\n",
    "        label_source_path = os.path.join(label_folder, label_file)\n",
    "        \n",
    "        # Tạo đường dẫn đích\n",
    "        image_dest_path = os.path.join(output_folder, 'images', image_file)\n",
    "        label_dest_path = os.path.join(output_folder, 'labels', label_file)\n",
    "        \n",
    "        # Sao chép tệp ảnh nếu tồn tại\n",
    "        if os.path.exists(image_source_path):\n",
    "            shutil.copy(image_source_path, image_dest_path)\n",
    "        else:\n",
    "            print(f\"Ảnh không tồn tại: {image_source_path}\")\n",
    "        \n",
    "        # Sao chép tệp nhãn nếu tồn tại\n",
    "        if os.path.exists(label_source_path):\n",
    "            shutil.copy(label_source_path, label_dest_path)\n",
    "        else:\n",
    "            print(f\"Nhãn không tồn tại: {label_source_path}\")\n",
    "\n",
    "# Ví dụ gọi hàm:\n",
    "copy_files_from_excel(\n",
    "    image_folder='/home/chaos/Downloads/images',\n",
    "    label_folder='/home/chaos/Downloads/labels',\n",
    "    excel_path='/home/chaos/Downloads/100examples.csv',\n",
    "    output_folder='/home/chaos/Documents/ChaosAIVision/Build-YOLO-v1-from-scratch/dataset'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chaos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
